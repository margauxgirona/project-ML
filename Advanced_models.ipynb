{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensembles et Modèles Avancés\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports principaux\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import clone\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1494, 35)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAY_ID</th>\n",
              "      <th>COUNTRY</th>\n",
              "      <th>DE_CONSUMPTION</th>\n",
              "      <th>FR_CONSUMPTION</th>\n",
              "      <th>DE_FR_EXCHANGE</th>\n",
              "      <th>FR_DE_EXCHANGE</th>\n",
              "      <th>DE_NET_EXPORT</th>\n",
              "      <th>FR_NET_EXPORT</th>\n",
              "      <th>DE_NET_IMPORT</th>\n",
              "      <th>FR_NET_IMPORT</th>\n",
              "      <th>...</th>\n",
              "      <th>DE_RAIN</th>\n",
              "      <th>FR_RAIN</th>\n",
              "      <th>DE_WIND</th>\n",
              "      <th>FR_WIND</th>\n",
              "      <th>DE_TEMP</th>\n",
              "      <th>FR_TEMP</th>\n",
              "      <th>GAS_RET</th>\n",
              "      <th>COAL_RET</th>\n",
              "      <th>CARBON_RET</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>206</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.210099</td>\n",
              "      <td>-0.427458</td>\n",
              "      <td>-0.606523</td>\n",
              "      <td>0.606523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.692860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.692860</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.172680</td>\n",
              "      <td>-0.556356</td>\n",
              "      <td>-0.790823</td>\n",
              "      <td>-0.283160</td>\n",
              "      <td>-1.069070</td>\n",
              "      <td>-0.063404</td>\n",
              "      <td>0.339041</td>\n",
              "      <td>0.124552</td>\n",
              "      <td>-0.002445</td>\n",
              "      <td>0.028313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>501</td>\n",
              "      <td>FR</td>\n",
              "      <td>-0.022399</td>\n",
              "      <td>-1.003452</td>\n",
              "      <td>-0.022063</td>\n",
              "      <td>0.022063</td>\n",
              "      <td>-0.573520</td>\n",
              "      <td>-1.130838</td>\n",
              "      <td>0.573520</td>\n",
              "      <td>1.130838</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.240300</td>\n",
              "      <td>-0.770457</td>\n",
              "      <td>1.522331</td>\n",
              "      <td>0.828412</td>\n",
              "      <td>0.437419</td>\n",
              "      <td>1.831241</td>\n",
              "      <td>-0.659091</td>\n",
              "      <td>0.047114</td>\n",
              "      <td>-0.490365</td>\n",
              "      <td>-0.112516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>687</td>\n",
              "      <td>FR</td>\n",
              "      <td>1.395035</td>\n",
              "      <td>1.978665</td>\n",
              "      <td>1.021305</td>\n",
              "      <td>-1.021305</td>\n",
              "      <td>-0.622021</td>\n",
              "      <td>-1.682587</td>\n",
              "      <td>0.622021</td>\n",
              "      <td>1.682587</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.480700</td>\n",
              "      <td>-0.313338</td>\n",
              "      <td>0.431134</td>\n",
              "      <td>0.487608</td>\n",
              "      <td>0.684884</td>\n",
              "      <td>0.114836</td>\n",
              "      <td>0.535974</td>\n",
              "      <td>0.743338</td>\n",
              "      <td>0.204952</td>\n",
              "      <td>-0.180840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>720</td>\n",
              "      <td>DE</td>\n",
              "      <td>-0.983324</td>\n",
              "      <td>-0.849198</td>\n",
              "      <td>-0.839586</td>\n",
              "      <td>0.839586</td>\n",
              "      <td>-0.270870</td>\n",
              "      <td>0.563230</td>\n",
              "      <td>0.270870</td>\n",
              "      <td>-0.563230</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.114838</td>\n",
              "      <td>-0.507570</td>\n",
              "      <td>-0.499409</td>\n",
              "      <td>-0.236249</td>\n",
              "      <td>0.350938</td>\n",
              "      <td>-0.417514</td>\n",
              "      <td>0.911652</td>\n",
              "      <td>-0.296168</td>\n",
              "      <td>1.073948</td>\n",
              "      <td>-0.260356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>818</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.143807</td>\n",
              "      <td>-0.617038</td>\n",
              "      <td>-0.924990</td>\n",
              "      <td>0.924990</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.990324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.990324</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.541465</td>\n",
              "      <td>-0.424550</td>\n",
              "      <td>-1.088158</td>\n",
              "      <td>-1.011560</td>\n",
              "      <td>0.614338</td>\n",
              "      <td>0.729495</td>\n",
              "      <td>0.245109</td>\n",
              "      <td>1.526606</td>\n",
              "      <td>2.614378</td>\n",
              "      <td>-0.071733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  DE_FR_EXCHANGE  \\\n",
              "0     206      FR        0.210099       -0.427458       -0.606523   \n",
              "1     501      FR       -0.022399       -1.003452       -0.022063   \n",
              "2     687      FR        1.395035        1.978665        1.021305   \n",
              "3     720      DE       -0.983324       -0.849198       -0.839586   \n",
              "4     818      FR        0.143807       -0.617038       -0.924990   \n",
              "\n",
              "   FR_DE_EXCHANGE  DE_NET_EXPORT  FR_NET_EXPORT  DE_NET_IMPORT  FR_NET_IMPORT  \\\n",
              "0        0.606523            NaN       0.692860            NaN      -0.692860   \n",
              "1        0.022063      -0.573520      -1.130838       0.573520       1.130838   \n",
              "2       -1.021305      -0.622021      -1.682587       0.622021       1.682587   \n",
              "3        0.839586      -0.270870       0.563230       0.270870      -0.563230   \n",
              "4        0.924990            NaN       0.990324            NaN      -0.990324   \n",
              "\n",
              "   ...   DE_RAIN   FR_RAIN   DE_WIND   FR_WIND   DE_TEMP   FR_TEMP   GAS_RET  \\\n",
              "0  ... -0.172680 -0.556356 -0.790823 -0.283160 -1.069070 -0.063404  0.339041   \n",
              "1  ... -1.240300 -0.770457  1.522331  0.828412  0.437419  1.831241 -0.659091   \n",
              "2  ... -0.480700 -0.313338  0.431134  0.487608  0.684884  0.114836  0.535974   \n",
              "3  ... -1.114838 -0.507570 -0.499409 -0.236249  0.350938 -0.417514  0.911652   \n",
              "4  ... -0.541465 -0.424550 -1.088158 -1.011560  0.614338  0.729495  0.245109   \n",
              "\n",
              "   COAL_RET  CARBON_RET    TARGET  \n",
              "0  0.124552   -0.002445  0.028313  \n",
              "1  0.047114   -0.490365 -0.112516  \n",
              "2  0.743338    0.204952 -0.180840  \n",
              "3 -0.296168    1.073948 -0.260356  \n",
              "4  1.526606    2.614378 -0.071733  \n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "X = pd.read_csv(\"X_train_NHkHMNU.csv\")\n",
        "y = pd.read_csv(\"y_train_ZAN5mwg.csv\")\n",
        "\n",
        "df = pd.concat([X, y], axis=1)\n",
        "df = df.drop(columns=df.columns[-2], axis=1)  \n",
        "\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de feature engineering reprises du notebook d'origine\n",
        "\n",
        "def drop_columns(df, columns):\n",
        "    for c in columns:\n",
        "        df.drop(columns=c, inplace=True, errors=\"ignore\")\n",
        "\n",
        "\n",
        "def compute_median(df):\n",
        "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
        "    return df[numeric_cols].median()\n",
        "\n",
        "\n",
        "def missing_values_changed_with_median(df, medians):\n",
        "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(medians[numeric_cols])\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_threshold_columns(df: pd.DataFrame, column_name: str, threshold: float, way: str):\n",
        "    message = column_name + \"_THRESHOLD_\" + str(threshold)\n",
        "    if way == \"sup\":\n",
        "        df[message] = df[column_name].where(df[column_name] >= threshold, 0)\n",
        "    else:\n",
        "        df[message] = df[column_name].where(df[column_name] <= threshold, 0)\n",
        "\n",
        "\n",
        "def compute_quantiles(df, low=0.25, high=0.75, coeff=5):\n",
        "    bounds = {}\n",
        "    for column in df.select_dtypes(include=[\"number\"]).columns:\n",
        "        Q1 = df[column].quantile(low)\n",
        "        Q3 = df[column].quantile(high)\n",
        "        delta = Q3 - Q1\n",
        "        bounds[column] = (Q1 - coeff * delta, Q3 + coeff * delta)\n",
        "    return bounds\n",
        "\n",
        "\n",
        "def outliers_filter(df, bounds):\n",
        "    filter_ = pd.Series(True, index=df.index)\n",
        "    for column, (low, high) in bounds.items():\n",
        "        if column in df.columns:\n",
        "            filter_ &= (df[column] >= low) & (df[column] <= high)\n",
        "    return filter_\n",
        "\n",
        "\n",
        "def feature_engineering(df, medians, threshold, columns_kept):\n",
        "    columns_name = [\"DE_NET_IMPORT\", \"FR_NET_IMPORT\", \"DE_FR_EXCHANGE\"]\n",
        "    drop_columns(df, columns_name)\n",
        "    drop_columns(df, [\"FR_COAL\"])\n",
        "\n",
        "    df = missing_values_changed_with_median(df, medians)\n",
        "\n",
        "    for key, value in threshold.items():\n",
        "        add_threshold_columns(df, key, value[0], value[1])\n",
        "\n",
        "    to_keep = [c for c in df.columns if (c in columns_kept) or (\"_THRESHOLD_\" in c)]\n",
        "    df = df[to_keep]\n",
        "    return df\n",
        "\n",
        "\n",
        "def transform_one_country(df, threshold, columns_kept, standardisation=True):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df.drop(columns=[\"TARGET\"]), df[\"TARGET\"], test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    medians = compute_median(X_train)\n",
        "\n",
        "    X_train = feature_engineering(X_train.copy(), medians, threshold, columns_kept)\n",
        "    X_test = feature_engineering(X_test.copy(), medians, threshold, columns_kept)\n",
        "\n",
        "    bounds = compute_quantiles(X_train)\n",
        "    filter_ = outliers_filter(X_train, bounds)\n",
        "    X_train = X_train[filter_]\n",
        "    y_train = y_train[filter_]\n",
        "\n",
        "    if standardisation:\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        X_train = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
        "        X_test = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X_test.columns)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def transform(df, threshold_fr, threshold_de, columns_kept_fr, columns_kept_de, standardisation=True):\n",
        "    df_fr = df[df[\"COUNTRY\"] == \"FR\"].copy()\n",
        "    df_de = df[df[\"COUNTRY\"] == \"DE\"].copy()\n",
        "\n",
        "    X_train_fr, X_test_fr, y_train_fr, y_test_fr = transform_one_country(\n",
        "        df_fr, threshold_fr, columns_kept_fr, standardisation=standardisation\n",
        "    )\n",
        "\n",
        "    X_train_de, X_test_de, y_train_de, y_test_de = transform_one_country(\n",
        "        df_de, threshold_de, columns_kept_de, standardisation=standardisation\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        X_train_fr,\n",
        "        X_test_fr,\n",
        "        y_train_fr,\n",
        "        y_test_fr,\n",
        "        X_train_de,\n",
        "        X_test_de,\n",
        "        y_train_de,\n",
        "        y_test_de,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France: 527 train / 171 test -- Germany: 443 train / 129 test\n"
          ]
        }
      ],
      "source": [
        "# Paramètres déjà validés dans le projet\n",
        "threshold_fr = {\n",
        "    \"COAL_RET\": [0.8, \"inf\"],\n",
        "    \"FR_CONSUMPTION\": [1.5, \"sup\"],\n",
        "    \"FR_NUCLEAR\": [-1.8, \"inf\"],\n",
        "    \"FR_HYDRO\": [-0.4, \"inf\"],\n",
        "}\n",
        "\n",
        "threshold_de = {\n",
        "    \"DE_CONSUMPTION\": [1.2, \"sup\"],\n",
        "    \"DE_NET_EXPORT\": [-0.45, \"sup\"],\n",
        "    \"DE_WINDPOW\": [0.3, \"sup\"],\n",
        "}\n",
        "\n",
        "columns_kept_fr = [\n",
        "    \"DE_NET_EXPORT\",\n",
        "    \"DE_HYDRO\",\n",
        "    \"DE_WINDPOW\",\n",
        "    \"FR_WINDPOW\",\n",
        "    \"GAS_RET\",\n",
        "    \"CARBON_RET\",\n",
        "]\n",
        "\n",
        "columns_kept_de = [\n",
        "    \"DE_NET_EXPORT\",\n",
        "    \"DE_GAS\",\n",
        "    \"DE_COAL\",\n",
        "    \"DE_HYDRO\",\n",
        "    \"DE_WINDPOW\",\n",
        "    \"FR_WINDPOW\",\n",
        "    \"DE_LIGNITE\",\n",
        "    \"DE_RESIDUAL_LOAD\",\n",
        "    \"DE_WIND\",\n",
        "]\n",
        "\n",
        "X_train_fr, X_test_fr, y_train_fr, y_test_fr, X_train_de, X_test_de, y_train_de, y_test_de = transform(\n",
        "    df,\n",
        "    threshold_fr,\n",
        "    threshold_de,\n",
        "    columns_kept_fr,\n",
        "    columns_kept_de,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"France: {X_train_fr.shape[0]} train / {X_test_fr.shape[0]} test -- \"\n",
        "    f\"Germany: {X_train_de.shape[0]} train / {X_test_de.shape[0]} test\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions utilitaires pour l'évaluation\n",
        "\n",
        "def spearman_corr(y_true, y_pred):\n",
        "    return spearmanr(y_true, y_pred).correlation\n",
        "\n",
        "\n",
        "def kfold_score(model, X, y, k=5):\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        model_ = clone(model)\n",
        "        model_.fit(X_train, y_train)\n",
        "        y_pred = model_.predict(X_val)\n",
        "        scores.append(spearman_corr(y_val, y_pred))\n",
        "    return float(np.mean(scores)), float(np.std(scores))\n",
        "\n",
        "#fonction pour recuperer les scores de chaque model directement\n",
        "def evaluate_simple(model, X_train, y_train, X_test, y_test, k=5):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred_test)\n",
        "    rmse = np.sqrt(mse)\n",
        "    kfold_mean, kfold_std = kfold_score(model, X_train, y_train, k=k)\n",
        "    return {\n",
        "        \"spearman_train\": float(spearman_corr(y_train, y_pred_train)),\n",
        "        \"spearman_test\": float(spearman_corr(y_test, y_pred_test)),\n",
        "        \"spearman_kfold\": float(kfold_mean),\n",
        "        \"spearman_std\": float(kfold_std),\n",
        "        \"r2_test\": float(r2_score(y_test, y_pred_test)),\n",
        "        \"rmse_test\": float(rmse),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - meilleurs hyperparamètres : {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
            "Germany - meilleurs hyperparamètres : {'max_depth': 3, 'min_samples_leaf': 20, 'min_samples_split': 5}\n",
            "France - KFold Spearman: mean=0.150, std=0.054\n",
            "Germany - KFold Spearman: mean=0.202, std=0.139\n"
          ]
        }
      ],
      "source": [
        "# 1) Decision Tree Regressor avec recherche de paramètres + K-Fold\n",
        "spearman_scorer = make_scorer(spearman_corr, greater_is_better=True)\n",
        "\n",
        "fr_param_grid = {\n",
        "    \"max_depth\": [3, 4, 5, 6, 7],\n",
        "    \"min_samples_leaf\": [5, 10, 20, 30, 50],\n",
        "    \"min_samples_split\": [5, 10, 20, 30],\n",
        "}\n",
        "\n",
        "de_param_grid = {\n",
        "    \"max_depth\": [3, 4, 5, 7, 10, 12],\n",
        "    \"min_samples_leaf\": [5, 10, 20, 30, 50],\n",
        "    \"min_samples_split\": [5, 10, 20],\n",
        "}\n",
        "\n",
        "fr_search = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    param_grid=fr_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "de_search = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    param_grid=de_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "fr_search.fit(X_train_fr, y_train_fr)\n",
        "fr_tree = fr_search.best_estimator_\n",
        "print(\"France - meilleurs hyperparamètres :\", fr_search.best_params_)\n",
        "\n",
        "de_search.fit(X_train_de, y_train_de)\n",
        "de_tree = de_search.best_estimator_\n",
        "print(\"Germany - meilleurs hyperparamètres :\", de_search.best_params_)\n",
        "\n",
        "fr_kfold = kfold_score(fr_tree, X_train_fr, y_train_fr, k=5)\n",
        "de_kfold = kfold_score(de_tree, X_train_de, y_train_de, k=5)\n",
        "\n",
        "print(f\"France - KFold Spearman: mean={fr_kfold[0]:.3f}, std={fr_kfold[1]:.3f}\")\n",
        "print(f\"Germany - KFold Spearman: mean={de_kfold[0]:.3f}, std={de_kfold[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - meilleurs hyperparamètres bagging : {'bootstrap': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 30}\n",
            "Germany - meilleurs hyperparamètres bagging : {'bootstrap': False, 'max_features': 0.7, 'max_samples': 0.9, 'n_estimators': 100}\n",
            "France - Bagging optimisé\n",
            "  Spearman test  : 0.071\n",
            "  Spearman train : 0.285\n",
            "Germany - Bagging optimisé\n",
            "  Spearman test  : 0.211\n",
            "  Spearman train : 0.487\n"
          ]
        }
      ],
      "source": [
        "# 2) Bagging sur Decision Tree \n",
        "base_fr_tree = DecisionTreeRegressor(**fr_search.best_params_, random_state=42)\n",
        "base_de_tree = DecisionTreeRegressor(**de_search.best_params_, random_state=42)\n",
        "\n",
        "bagging_fr_param_grid = {\n",
        "    \"n_estimators\": [30, 50, 80],\n",
        "    \"max_samples\": [0.6, 0.8, 1.0],\n",
        "    \"max_features\": [0.8, 1.0],\n",
        "    \"bootstrap\": [True, False],\n",
        "}\n",
        "\n",
        "bagging_de_param_grid = {\n",
        "    \"n_estimators\": [30, 60, 100],\n",
        "    \"max_samples\": [0.6, 0.9, 1.0],\n",
        "    \"max_features\": [0.7, 1.0],\n",
        "    \"bootstrap\": [True, False],\n",
        "}\n",
        "\n",
        "bagging_fr_search = GridSearchCV(\n",
        "    BaggingRegressor(estimator=base_fr_tree, random_state=42),\n",
        "    param_grid=bagging_fr_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "bagging_de_search = GridSearchCV(\n",
        "    BaggingRegressor(estimator=base_de_tree, random_state=42),\n",
        "    param_grid=bagging_de_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "bagging_fr_search.fit(X_train_fr, y_train_fr)\n",
        "bagging_fr = bagging_fr_search.best_estimator_\n",
        "print(\"France - meilleurs hyperparamètres bagging :\", bagging_fr_search.best_params_)\n",
        "\n",
        "bagging_de_search.fit(X_train_de, y_train_de)\n",
        "bagging_de = bagging_de_search.best_estimator_\n",
        "print(\"Germany - meilleurs hyperparamètres bagging :\", bagging_de_search.best_params_)\n",
        "\n",
        "bagging_fr_metrics = evaluate_simple(bagging_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "bagging_de_metrics = evaluate_simple(bagging_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "print(\"France - Bagging optimisé\")\n",
        "print(f\"  Spearman test  : {bagging_fr_metrics['spearman_test']:.3f}\")\n",
        "print(f\"  Spearman train : {bagging_fr_metrics['spearman_train']:.3f}\")\n",
        "print(\"Germany - Bagging optimisé\")\n",
        "print(f\"  Spearman test  : {bagging_de_metrics['spearman_test']:.3f}\")\n",
        "print(f\"  Spearman train : {bagging_de_metrics['spearman_train']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultats pas bon non plus, le baggin n'apporte pas de changement important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - meilleurs hyperparamètres SVR : {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Germany - meilleurs hyperparamètres SVR : {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "France - SVR optimisé {'spearman_train': 0.258054443488878, 'spearman_test': 0.22184475834882816, 'spearman_kfold': 0.21711805518813038, 'spearman_std': 0.10847272088092935, 'r2_test': 0.00932940725532061, 'rmse_test': 1.1818609558511215}\n",
            "Germany - SVR optimisé {'spearman_train': 0.3152258369917798, 'spearman_test': 0.37359682468694105, 'spearman_kfold': 0.27390404160235177, 'spearman_std': 0.1278410551302806, 'r2_test': 0.026519451394977023, 'rmse_test': 0.963154599695358}\n"
          ]
        }
      ],
      "source": [
        "# 3) SVM (SVR) avec GridSearch \n",
        "svr_param_grid = {\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"kernel\": [\"linear\", \"rbf\"],\n",
        "    \"gamma\": [\"scale\", \"auto\"],\n",
        "}\n",
        "\n",
        "svr_fr_search = GridSearchCV(\n",
        "    SVR(epsilon=0.1),\n",
        "    param_grid=svr_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "svr_fr_search.fit(X_train_fr, y_train_fr)\n",
        "svr_fr = svr_fr_search.best_estimator_\n",
        "print(\"France - meilleurs hyperparamètres SVR :\", svr_fr_search.best_params_)\n",
        "\n",
        "svr_de_search = GridSearchCV(\n",
        "    SVR(epsilon=0.1),\n",
        "    param_grid=svr_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "svr_de_search.fit(X_train_de, y_train_de)\n",
        "svr_de = svr_de_search.best_estimator_\n",
        "print(\"Germany - meilleurs hyperparamètres SVR :\", svr_de_search.best_params_)\n",
        "\n",
        "svr_fr_metrics = evaluate_simple(svr_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "svr_de_metrics = evaluate_simple(svr_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "print(\"France - SVR optimisé\", svr_fr_metrics)\n",
        "print(\"Germany - SVR optimisé\", svr_de_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "mieux que pour le decision tree mais le r² reste tres mauvais donc peu interessant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - Random Forest {'spearman_train': 0.47569906268285644, 'spearman_test': 0.19730253996123978, 'spearman_kfold': 0.14865402867054464, 'spearman_std': 0.07712237886188927, 'r2_test': 0.012698839215019797, 'rmse_test': 1.1798493932268128}\n",
            "Germany - Random Forest {'spearman_train': 0.6802854052275341, 'spearman_test': 0.2264031753130591, 'spearman_kfold': 0.24473379313375196, 'spearman_std': 0.1083541617965652, 'r2_test': 0.03846469950693754, 'rmse_test': 0.9572270889975645}\n"
          ]
        }
      ],
      "source": [
        "# 4) Random Forest (simple réglages)\n",
        "rf_fr = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=8,\n",
        "    min_samples_leaf=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "rf_de = RandomForestRegressor(\n",
        "    n_estimators=400,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "rf_fr_metrics = evaluate_simple(rf_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "rf_de_metrics = evaluate_simple(rf_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "print(\"France - Random Forest\", rf_fr_metrics)\n",
        "print(\"Germany - Random Forest\", rf_de_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - XGBoost {'spearman_train': 0.5488196556407897, 'spearman_test': 0.21093923904966902, 'spearman_kfold': 0.12671876636773632, 'spearman_std': 0.03497917600333644, 'r2_test': 0.01866402643504894, 'rmse_test': 1.17627971974826}\n",
            "Germany - XGBoost {'spearman_train': 0.6806106030144915, 'spearman_test': 0.2218358676207514, 'spearman_kfold': 0.23729051335282772, 'spearman_std': 0.11896660178511997, 'r2_test': -0.0028596275131647086, 'rmse_test': 0.9775802928246266}\n"
          ]
        }
      ],
      "source": [
        "xgb_fr = XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.03,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_lambda=2.0,\n",
        "    reg_alpha=1.0,\n",
        "    objective=\"reg:squarederror\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "\n",
        "xgb_de = XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.03,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_lambda=2.0,\n",
        "    reg_alpha=1.0,\n",
        "    objective=\"reg:squarederror\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "xgb_fr_metrics = evaluate_simple(xgb_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "xgb_de_metrics = evaluate_simple(xgb_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "print(\"France - XGBoost\", xgb_fr_metrics)\n",
        "print(\"Germany - XGBoost\", xgb_de_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "overfitting assez important\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>country</th>\n",
              "      <th>spearman_train</th>\n",
              "      <th>spearman_test</th>\n",
              "      <th>spearman_std</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.279005</td>\n",
              "      <td>0.038782</td>\n",
              "      <td>0.053511</td>\n",
              "      <td>kfold + test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.363090</td>\n",
              "      <td>0.123328</td>\n",
              "      <td>0.139108</td>\n",
              "      <td>kfold + test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DecisionTree_Bagging</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.284972</td>\n",
              "      <td>0.070668</td>\n",
              "      <td>0.053511</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTree_Bagging</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.486671</td>\n",
              "      <td>0.210689</td>\n",
              "      <td>0.111035</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVR</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.258054</td>\n",
              "      <td>0.221845</td>\n",
              "      <td>0.108473</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SVR</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.315226</td>\n",
              "      <td>0.373597</td>\n",
              "      <td>0.127841</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.475699</td>\n",
              "      <td>0.197303</td>\n",
              "      <td>0.077122</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.680285</td>\n",
              "      <td>0.226403</td>\n",
              "      <td>0.108354</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.548820</td>\n",
              "      <td>0.210939</td>\n",
              "      <td>0.034979</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.680611</td>\n",
              "      <td>0.221836</td>\n",
              "      <td>0.118967</td>\n",
              "      <td>test simple</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  model country  spearman_train  spearman_test  spearman_std  \\\n",
              "0          DecisionTree      FR        0.279005       0.038782      0.053511   \n",
              "1          DecisionTree      DE        0.363090       0.123328      0.139108   \n",
              "2  DecisionTree_Bagging      FR        0.284972       0.070668      0.053511   \n",
              "3  DecisionTree_Bagging      DE        0.486671       0.210689      0.111035   \n",
              "4                   SVR      FR        0.258054       0.221845      0.108473   \n",
              "5                   SVR      DE        0.315226       0.373597      0.127841   \n",
              "6          RandomForest      FR        0.475699       0.197303      0.077122   \n",
              "7          RandomForest      DE        0.680285       0.226403      0.108354   \n",
              "8               XGBoost      FR        0.548820       0.210939      0.034979   \n",
              "9               XGBoost      DE        0.680611       0.221836      0.118967   \n",
              "\n",
              "           note  \n",
              "0  kfold + test  \n",
              "1  kfold + test  \n",
              "2   test simple  \n",
              "3   test simple  \n",
              "4   test simple  \n",
              "5   test simple  \n",
              "6   test simple  \n",
              "7   test simple  \n",
              "8   test simple  \n",
              "9   test simple  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "summary_rows = []\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman_train\": fr_tree_holdout[\"spearman_train\"],\n",
        "    \"spearman_test\": fr_tree_holdout[\"spearman_test\"],\n",
        "    \"spearman_std\": fr_kfold[1],\n",
        "    \"note\": \"kfold + test\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman_train\": de_tree_holdout[\"spearman_train\"],\n",
        "    \"spearman_test\": de_tree_holdout[\"spearman_test\"],\n",
        "    \"spearman_std\": de_kfold[1],\n",
        "    \"note\": \"kfold + test\",\n",
        "})\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree_Bagging\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman_train\": bagging_fr_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": bagging_fr_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": bagging_fr_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree_Bagging\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman_train\": bagging_de_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": bagging_de_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": bagging_de_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"SVR\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman_train\": svr_fr_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": svr_fr_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": svr_fr_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"SVR\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman_train\": svr_de_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": svr_de_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": svr_de_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"RandomForest\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman_train\": rf_fr_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": rf_fr_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": rf_fr_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"RandomForest\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman_train\": rf_de_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": rf_de_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": rf_de_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"XGBoost\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman_train\": xgb_fr_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": xgb_fr_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": xgb_fr_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"XGBoost\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman_train\": xgb_de_metrics[\"spearman_train\"],\n",
        "    \"spearman_test\": xgb_de_metrics[\"spearman_test\"],\n",
        "    \"spearman_std\": xgb_de_metrics[\"spearman_std\"],\n",
        "    \"note\": \"test simple\",\n",
        "})\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "display(summary_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion rapide\n",
        "- Le modèle Decision Tree = résultats modestes : il capte partiellement les relations entre les variables et fait de l'overfitting\n",
        "- Le Bagging = améliore légèrement la stabilité du modèle en réduisant la variance, mais les gains en performance restent vachement limités.\n",
        "- Le SVM = meilleure cohérence dans les prédictions et parvient à suivre plus fidèlement la tendance générale, sans modéliser précisément la variabilité des données.\n",
        "- Le Random Forest = extrait des relations plus complexes et offre de meilleurs scores de corrélation tout en restant relativement robuste.\n",
        "- XGBoost = le modèle le plus performant dans l’ensemble, mais il fait quand même pas mal d'overfitting."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
