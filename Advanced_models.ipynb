{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensembles et Modèles Avancés\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports principaux\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import clone\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1494, 35)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAY_ID</th>\n",
              "      <th>COUNTRY</th>\n",
              "      <th>DE_CONSUMPTION</th>\n",
              "      <th>FR_CONSUMPTION</th>\n",
              "      <th>DE_FR_EXCHANGE</th>\n",
              "      <th>FR_DE_EXCHANGE</th>\n",
              "      <th>DE_NET_EXPORT</th>\n",
              "      <th>FR_NET_EXPORT</th>\n",
              "      <th>DE_NET_IMPORT</th>\n",
              "      <th>FR_NET_IMPORT</th>\n",
              "      <th>...</th>\n",
              "      <th>DE_RAIN</th>\n",
              "      <th>FR_RAIN</th>\n",
              "      <th>DE_WIND</th>\n",
              "      <th>FR_WIND</th>\n",
              "      <th>DE_TEMP</th>\n",
              "      <th>FR_TEMP</th>\n",
              "      <th>GAS_RET</th>\n",
              "      <th>COAL_RET</th>\n",
              "      <th>CARBON_RET</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>206</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.210099</td>\n",
              "      <td>-0.427458</td>\n",
              "      <td>-0.606523</td>\n",
              "      <td>0.606523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.692860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.692860</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.172680</td>\n",
              "      <td>-0.556356</td>\n",
              "      <td>-0.790823</td>\n",
              "      <td>-0.283160</td>\n",
              "      <td>-1.069070</td>\n",
              "      <td>-0.063404</td>\n",
              "      <td>0.339041</td>\n",
              "      <td>0.124552</td>\n",
              "      <td>-0.002445</td>\n",
              "      <td>0.028313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>501</td>\n",
              "      <td>FR</td>\n",
              "      <td>-0.022399</td>\n",
              "      <td>-1.003452</td>\n",
              "      <td>-0.022063</td>\n",
              "      <td>0.022063</td>\n",
              "      <td>-0.573520</td>\n",
              "      <td>-1.130838</td>\n",
              "      <td>0.573520</td>\n",
              "      <td>1.130838</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.240300</td>\n",
              "      <td>-0.770457</td>\n",
              "      <td>1.522331</td>\n",
              "      <td>0.828412</td>\n",
              "      <td>0.437419</td>\n",
              "      <td>1.831241</td>\n",
              "      <td>-0.659091</td>\n",
              "      <td>0.047114</td>\n",
              "      <td>-0.490365</td>\n",
              "      <td>-0.112516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>687</td>\n",
              "      <td>FR</td>\n",
              "      <td>1.395035</td>\n",
              "      <td>1.978665</td>\n",
              "      <td>1.021305</td>\n",
              "      <td>-1.021305</td>\n",
              "      <td>-0.622021</td>\n",
              "      <td>-1.682587</td>\n",
              "      <td>0.622021</td>\n",
              "      <td>1.682587</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.480700</td>\n",
              "      <td>-0.313338</td>\n",
              "      <td>0.431134</td>\n",
              "      <td>0.487608</td>\n",
              "      <td>0.684884</td>\n",
              "      <td>0.114836</td>\n",
              "      <td>0.535974</td>\n",
              "      <td>0.743338</td>\n",
              "      <td>0.204952</td>\n",
              "      <td>-0.180840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>720</td>\n",
              "      <td>DE</td>\n",
              "      <td>-0.983324</td>\n",
              "      <td>-0.849198</td>\n",
              "      <td>-0.839586</td>\n",
              "      <td>0.839586</td>\n",
              "      <td>-0.270870</td>\n",
              "      <td>0.563230</td>\n",
              "      <td>0.270870</td>\n",
              "      <td>-0.563230</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.114838</td>\n",
              "      <td>-0.507570</td>\n",
              "      <td>-0.499409</td>\n",
              "      <td>-0.236249</td>\n",
              "      <td>0.350938</td>\n",
              "      <td>-0.417514</td>\n",
              "      <td>0.911652</td>\n",
              "      <td>-0.296168</td>\n",
              "      <td>1.073948</td>\n",
              "      <td>-0.260356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>818</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.143807</td>\n",
              "      <td>-0.617038</td>\n",
              "      <td>-0.924990</td>\n",
              "      <td>0.924990</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.990324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.990324</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.541465</td>\n",
              "      <td>-0.424550</td>\n",
              "      <td>-1.088158</td>\n",
              "      <td>-1.011560</td>\n",
              "      <td>0.614338</td>\n",
              "      <td>0.729495</td>\n",
              "      <td>0.245109</td>\n",
              "      <td>1.526606</td>\n",
              "      <td>2.614378</td>\n",
              "      <td>-0.071733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  DE_FR_EXCHANGE  \\\n",
              "0     206      FR        0.210099       -0.427458       -0.606523   \n",
              "1     501      FR       -0.022399       -1.003452       -0.022063   \n",
              "2     687      FR        1.395035        1.978665        1.021305   \n",
              "3     720      DE       -0.983324       -0.849198       -0.839586   \n",
              "4     818      FR        0.143807       -0.617038       -0.924990   \n",
              "\n",
              "   FR_DE_EXCHANGE  DE_NET_EXPORT  FR_NET_EXPORT  DE_NET_IMPORT  FR_NET_IMPORT  \\\n",
              "0        0.606523            NaN       0.692860            NaN      -0.692860   \n",
              "1        0.022063      -0.573520      -1.130838       0.573520       1.130838   \n",
              "2       -1.021305      -0.622021      -1.682587       0.622021       1.682587   \n",
              "3        0.839586      -0.270870       0.563230       0.270870      -0.563230   \n",
              "4        0.924990            NaN       0.990324            NaN      -0.990324   \n",
              "\n",
              "   ...   DE_RAIN   FR_RAIN   DE_WIND   FR_WIND   DE_TEMP   FR_TEMP   GAS_RET  \\\n",
              "0  ... -0.172680 -0.556356 -0.790823 -0.283160 -1.069070 -0.063404  0.339041   \n",
              "1  ... -1.240300 -0.770457  1.522331  0.828412  0.437419  1.831241 -0.659091   \n",
              "2  ... -0.480700 -0.313338  0.431134  0.487608  0.684884  0.114836  0.535974   \n",
              "3  ... -1.114838 -0.507570 -0.499409 -0.236249  0.350938 -0.417514  0.911652   \n",
              "4  ... -0.541465 -0.424550 -1.088158 -1.011560  0.614338  0.729495  0.245109   \n",
              "\n",
              "   COAL_RET  CARBON_RET    TARGET  \n",
              "0  0.124552   -0.002445  0.028313  \n",
              "1  0.047114   -0.490365 -0.112516  \n",
              "2  0.743338    0.204952 -0.180840  \n",
              "3 -0.296168    1.073948 -0.260356  \n",
              "4  1.526606    2.614378 -0.071733  \n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Chargement des données préparées précédemment\n",
        "X = pd.read_csv(\"X_train_NHkHMNU.csv\")\n",
        "y = pd.read_csv(\"y_train_ZAN5mwg.csv\")\n",
        "\n",
        "df = pd.concat([X, y], axis=1)\n",
        "df = df.drop(columns=df.columns[-2], axis=1)  # même astuce que dans l'autre notebook\n",
        "\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions de feature engineering reprises du notebook d'origine\n",
        "\n",
        "def drop_columns(df, columns):\n",
        "    for c in columns:\n",
        "        df.drop(columns=c, inplace=True, errors=\"ignore\")\n",
        "\n",
        "\n",
        "def compute_median(df):\n",
        "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
        "    return df[numeric_cols].median()\n",
        "\n",
        "\n",
        "def missing_values_changed_with_median(df, medians):\n",
        "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(medians[numeric_cols])\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_threshold_columns(df: pd.DataFrame, column_name: str, threshold: float, way: str):\n",
        "    message = column_name + \"_THRESHOLD_\" + str(threshold)\n",
        "    if way == \"sup\":\n",
        "        df[message] = df[column_name].where(df[column_name] >= threshold, 0)\n",
        "    else:\n",
        "        df[message] = df[column_name].where(df[column_name] <= threshold, 0)\n",
        "\n",
        "\n",
        "def compute_quantiles(df, low=0.25, high=0.75, coeff=5):\n",
        "    bounds = {}\n",
        "    for column in df.select_dtypes(include=[\"number\"]).columns:\n",
        "        Q1 = df[column].quantile(low)\n",
        "        Q3 = df[column].quantile(high)\n",
        "        delta = Q3 - Q1\n",
        "        bounds[column] = (Q1 - coeff * delta, Q3 + coeff * delta)\n",
        "    return bounds\n",
        "\n",
        "\n",
        "def outliers_filter(df, bounds):\n",
        "    filter_ = pd.Series(True, index=df.index)\n",
        "    for column, (low, high) in bounds.items():\n",
        "        if column in df.columns:\n",
        "            filter_ &= (df[column] >= low) & (df[column] <= high)\n",
        "    return filter_\n",
        "\n",
        "\n",
        "def feature_engineering(df, medians, threshold, columns_kept):\n",
        "    columns_name = [\"DE_NET_IMPORT\", \"FR_NET_IMPORT\", \"DE_FR_EXCHANGE\"]\n",
        "    drop_columns(df, columns_name)\n",
        "    drop_columns(df, [\"FR_COAL\"])\n",
        "\n",
        "    df = missing_values_changed_with_median(df, medians)\n",
        "\n",
        "    for key, value in threshold.items():\n",
        "        add_threshold_columns(df, key, value[0], value[1])\n",
        "\n",
        "    to_keep = [c for c in df.columns if (c in columns_kept) or (\"_THRESHOLD_\" in c)]\n",
        "    df = df[to_keep]\n",
        "    return df\n",
        "\n",
        "\n",
        "def transform_one_country(df, threshold, columns_kept, standardisation=True):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df.drop(columns=[\"TARGET\"]), df[\"TARGET\"], test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    medians = compute_median(X_train)\n",
        "\n",
        "    X_train = feature_engineering(X_train.copy(), medians, threshold, columns_kept)\n",
        "    X_test = feature_engineering(X_test.copy(), medians, threshold, columns_kept)\n",
        "\n",
        "    bounds = compute_quantiles(X_train)\n",
        "    filter_ = outliers_filter(X_train, bounds)\n",
        "    X_train = X_train[filter_]\n",
        "    y_train = y_train[filter_]\n",
        "\n",
        "    if standardisation:\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        X_train = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
        "        X_test = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X_test.columns)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def transform(df, threshold_fr, threshold_de, columns_kept_fr, columns_kept_de, standardisation=True):\n",
        "    df_fr = df[df[\"COUNTRY\"] == \"FR\"].copy()\n",
        "    df_de = df[df[\"COUNTRY\"] == \"DE\"].copy()\n",
        "\n",
        "    X_train_fr, X_test_fr, y_train_fr, y_test_fr = transform_one_country(\n",
        "        df_fr, threshold_fr, columns_kept_fr, standardisation=standardisation\n",
        "    )\n",
        "\n",
        "    X_train_de, X_test_de, y_train_de, y_test_de = transform_one_country(\n",
        "        df_de, threshold_de, columns_kept_de, standardisation=standardisation\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        X_train_fr,\n",
        "        X_test_fr,\n",
        "        y_train_fr,\n",
        "        y_test_fr,\n",
        "        X_train_de,\n",
        "        X_test_de,\n",
        "        y_train_de,\n",
        "        y_test_de,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France: 527 train / 171 test -- Germany: 443 train / 129 test\n"
          ]
        }
      ],
      "source": [
        "# Paramètres déjà validés dans le projet\n",
        "threshold_fr = {\n",
        "    \"COAL_RET\": [0.8, \"inf\"],\n",
        "    \"FR_CONSUMPTION\": [1.5, \"sup\"],\n",
        "    \"FR_NUCLEAR\": [-1.8, \"inf\"],\n",
        "    \"FR_HYDRO\": [-0.4, \"inf\"],\n",
        "}\n",
        "\n",
        "threshold_de = {\n",
        "    \"DE_CONSUMPTION\": [1.2, \"sup\"],\n",
        "    \"DE_NET_EXPORT\": [-0.45, \"sup\"],\n",
        "    \"DE_WINDPOW\": [0.3, \"sup\"],\n",
        "}\n",
        "\n",
        "columns_kept_fr = [\n",
        "    \"DE_NET_EXPORT\",\n",
        "    \"DE_HYDRO\",\n",
        "    \"DE_WINDPOW\",\n",
        "    \"FR_WINDPOW\",\n",
        "    \"GAS_RET\",\n",
        "    \"CARBON_RET\",\n",
        "]\n",
        "\n",
        "columns_kept_de = [\n",
        "    \"DE_NET_EXPORT\",\n",
        "    \"DE_GAS\",\n",
        "    \"DE_COAL\",\n",
        "    \"DE_HYDRO\",\n",
        "    \"DE_WINDPOW\",\n",
        "    \"FR_WINDPOW\",\n",
        "    \"DE_LIGNITE\",\n",
        "    \"DE_RESIDUAL_LOAD\",\n",
        "    \"DE_WIND\",\n",
        "]\n",
        "\n",
        "X_train_fr, X_test_fr, y_train_fr, y_test_fr, X_train_de, X_test_de, y_train_de, y_test_de = transform(\n",
        "    df,\n",
        "    threshold_fr,\n",
        "    threshold_de,\n",
        "    columns_kept_fr,\n",
        "    columns_kept_de,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"France: {X_train_fr.shape[0]} train / {X_test_fr.shape[0]} test -- \"\n",
        "    f\"Germany: {X_train_de.shape[0]} train / {X_test_de.shape[0]} test\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonctions utilitaires pour l'évaluation\n",
        "\n",
        "def spearman_corr(y_true, y_pred):\n",
        "    return spearmanr(y_true, y_pred).correlation\n",
        "\n",
        "\n",
        "def kfold_score(model, X, y, k=5):\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        model_ = clone(model)\n",
        "        model_.fit(X_train, y_train)\n",
        "        y_pred = model_.predict(X_val)\n",
        "        scores.append(spearman_corr(y_val, y_pred))\n",
        "    return float(np.mean(scores)), float(np.std(scores))\n",
        "\n",
        "#fonction pour recuperer les scores de chaque model directement\n",
        "def evaluate_simple(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred_test)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return {\n",
        "        \"spearman_train\": float(spearman_corr(y_train, y_pred_train)),\n",
        "        \"spearman_test\": float(spearman_corr(y_test, y_pred_test)),\n",
        "        \"r2_test\": float(r2_score(y_test, y_pred_test)),\n",
        "        \"rmse_test\": float(rmse),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - meilleurs hyperparamètres : {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
            "Germany - meilleurs hyperparamètres : {'max_depth': 3, 'min_samples_leaf': 20, 'min_samples_split': 5}\n",
            "France - KFold Spearman: mean=0.150, std=0.054\n",
            "Germany - KFold Spearman: mean=0.202, std=0.139\n"
          ]
        }
      ],
      "source": [
        "# 1) Decision Tree Regressor avec recherche de paramètres + K-Fold\n",
        "spearman_scorer = make_scorer(spearman_corr, greater_is_better=True)\n",
        "\n",
        "fr_param_grid = {\n",
        "    \"max_depth\": [3, 4, 5, 6, 7],\n",
        "    \"min_samples_leaf\": [5, 10, 20, 30, 50],\n",
        "    \"min_samples_split\": [5, 10, 20, 30],\n",
        "}\n",
        "\n",
        "de_param_grid = {\n",
        "    \"max_depth\": [3, 4, 5, 7, 10, 12],\n",
        "    \"min_samples_leaf\": [5, 10, 20, 30, 50],\n",
        "    \"min_samples_split\": [5, 10, 20],\n",
        "}\n",
        "\n",
        "fr_search = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    param_grid=fr_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "de_search = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    param_grid=de_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "fr_search.fit(X_train_fr, y_train_fr)\n",
        "fr_tree = fr_search.best_estimator_\n",
        "print(\"France - meilleurs hyperparamètres :\", fr_search.best_params_)\n",
        "\n",
        "de_search.fit(X_train_de, y_train_de)\n",
        "de_tree = de_search.best_estimator_\n",
        "print(\"Germany - meilleurs hyperparamètres :\", de_search.best_params_)\n",
        "\n",
        "fr_kfold = kfold_score(fr_tree, X_train_fr, y_train_fr, k=5)\n",
        "de_kfold = kfold_score(de_tree, X_train_de, y_train_de, k=5)\n",
        "\n",
        "print(f\"France - KFold Spearman: mean={fr_kfold[0]:.3f}, std={fr_kfold[1]:.3f}\")\n",
        "print(f\"Germany - KFold Spearman: mean={de_kfold[0]:.3f}, std={de_kfold[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - Bagging vs KFold\n",
            "  Spearman hold-out: 0.180\n",
            "  Spearman train   : 0.432\n",
            "Germany - Bagging vs KFold\n",
            "  Spearman hold-out: 0.206\n",
            "  Spearman train   : 0.580\n"
          ]
        }
      ],
      "source": [
        "# 2) Bagging sur Decision Tree avec petite recherche d'hyperparamètres\n",
        "base_fr_tree = DecisionTreeRegressor(**fr_search.best_params_, random_state=42)\n",
        "base_de_tree = DecisionTreeRegressor(**de_search.best_params_, random_state=42)\n",
        "\n",
        "bagging_fr_param_grid = {\n",
        "    \"n_estimators\": [30, 50, 80],\n",
        "    \"max_samples\": [0.6, 0.8, 1.0],\n",
        "    \"max_features\": [0.8, 1.0],\n",
        "    \"bootstrap\": [True, False],\n",
        "}\n",
        "\n",
        "bagging_de_param_grid = {\n",
        "    \"n_estimators\": [30, 60, 100],\n",
        "    \"max_samples\": [0.6, 0.9, 1.0],\n",
        "    \"max_features\": [0.7, 1.0],\n",
        "    \"bootstrap\": [True, False],\n",
        "}\n",
        "\n",
        "bagging_fr_search = GridSearchCV(\n",
        "    BaggingRegressor(estimator=base_fr_tree, random_state=42),\n",
        "    param_grid=bagging_fr_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "bagging_fr_search.fit(X_train_fr, y_train_fr)\n",
        "bagging_fr = bagging_fr_search.best_estimator_\n",
        "print(\"France - meilleurs hyperparamètres bagging :\", bagging_fr_search.best_params_)\n",
        "\n",
        "bagging_de_search = GridSearchCV(\n",
        "    BaggingRegressor(estimator=base_de_tree, random_state=42),\n",
        "    param_grid=bagging_de_param_grid,\n",
        "    scoring=spearman_scorer,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "bagging_de_search.fit(X_train_de, y_train_de)\n",
        "bagging_de = bagging_de_search.best_estimator_\n",
        "print(\"Germany - meilleurs hyperparamètres bagging :\", bagging_de_search.best_params_)\n",
        "\n",
        "bagging_fr_metrics = evaluate_simple(bagging_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "bagging_de_metrics = evaluate_simple(bagging_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "print(\"France - Bagging optimisé\")\n",
        "print(f\"  Spearman hold-out: {bagging_fr_metrics['spearman_test']:.3f}\")\n",
        "print(f\"  Spearman train   : {bagging_fr_metrics['spearman_train']:.3f}\")\n",
        "print(\"Germany - Bagging optimisé\")\n",
        "print(f\"  Spearman hold-out: {bagging_de_metrics['spearman_test']:.3f}\")\n",
        "print(f\"  Spearman train   : {bagging_de_metrics['spearman_train']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les cellules précédentes permettent de comparer directement la moyenne du Spearman obtenu avec le K-Fold (référence du pipeline actuel) et le score hold-out du Bagging. On obtient ainsi une vision claire du gain/perte de stabilité en remplaçant la validation croisée par un ensemble baggé sur les arbres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - SVR {'spearman_train': 0.6436868657986635, 'spearman_test': 0.24208620856210022, 'r2_test': 0.014304828204079856, 'rmse_test': 1.1788894043251976}\n",
            "Germany - SVR {'spearman_train': 0.6173299570827954, 'spearman_test': 0.2812723613595707, 'r2_test': -0.000896226328831462, 'rmse_test': 0.9766228693649052}\n"
          ]
        }
      ],
      "source": [
        "# 3) SVM (SVR) sur les deux pays\n",
        "svr_fr = SVR(kernel=\"rbf\", C=1.0, epsilon=0.1, gamma=\"scale\")\n",
        "svr_de = SVR(kernel=\"rbf\", C=1.0, epsilon=0.1, gamma=\"scale\")\n",
        "\n",
        "svr_fr_metrics = evaluate_simple(svr_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "svr_de_metrics = evaluate_simple(svr_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "print(\"France - SVR\", svr_fr_metrics)\n",
        "print(\"Germany - SVR\", svr_de_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - Random Forest {'spearman_train': 0.47569906268285644, 'spearman_test': 0.19730253996123978, 'r2_test': 0.012698839215019575, 'rmse_test': 1.1798493932268128}\n",
            "Germany - Random Forest {'spearman_train': 0.6802854052275341, 'spearman_test': 0.2264031753130591, 'r2_test': 0.03846469950693743, 'rmse_test': 0.9572270889975646}\n"
          ]
        }
      ],
      "source": [
        "# 4) Random Forest (simple réglages)\n",
        "rf_fr = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=8,\n",
        "    min_samples_leaf=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "rf_de = RandomForestRegressor(\n",
        "    n_estimators=400,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "rf_fr_metrics = evaluate_simple(rf_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "rf_de_metrics = evaluate_simple(rf_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "print(\"France - Random Forest\", rf_fr_metrics)\n",
        "print(\"Germany - Random Forest\", rf_de_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "France - XGBoost {'spearman_train': 0.9459175459177872, 'spearman_test': 0.22669152248277447, 'r2_test': -0.04491863252014694, 'rmse_test': 1.2137884104041166}\n",
            "Germany - XGBoost {'spearman_train': 0.9998424736950918, 'spearman_test': 0.14881484794275493, 'r2_test': -0.11894051411467887, 'rmse_test': 1.0326088987650484}\n"
          ]
        }
      ],
      "source": [
        "# 5) XGBoost (si disponible dans l'environnement)\n",
        "if XGBOOST_AVAILABLE:\n",
        "    xgb_fr = XGBRegressor(\n",
        "        n_estimators=600,\n",
        "        max_depth=4,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        objective=\"reg:squarederror\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    xgb_de = XGBRegressor(\n",
        "        n_estimators=800,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        objective=\"reg:squarederror\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    xgb_fr_metrics = evaluate_simple(xgb_fr, X_train_fr, y_train_fr, X_test_fr, y_test_fr)\n",
        "    xgb_de_metrics = evaluate_simple(xgb_de, X_train_de, y_train_de, X_test_de, y_test_de)\n",
        "\n",
        "    print(\"France - XGBoost\", xgb_fr_metrics)\n",
        "    print(\"Germany - XGBoost\", xgb_de_metrics)\n",
        "else:\n",
        "    print(\"XGBoost n'est pas installé. Lancer `pip install xgboost` puis ré exécuter cette cellule.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>country</th>\n",
              "      <th>spearman</th>\n",
              "      <th>std</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DecisionTree_KFold</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.058745</td>\n",
              "      <td>0.063139</td>\n",
              "      <td>validation croisée</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree_KFold</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.054465</td>\n",
              "      <td>0.083993</td>\n",
              "      <td>validation croisée</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DecisionTree_Bagging</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.180239</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTree_Bagging</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.206300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVR</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.242086</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SVR</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.281272</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.197303</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.226403</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>FR</td>\n",
              "      <td>0.226692</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>DE</td>\n",
              "      <td>0.148815</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hold-out</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  model country  spearman       std                note\n",
              "0    DecisionTree_KFold      FR  0.058745  0.063139  validation croisée\n",
              "1    DecisionTree_KFold      DE  0.054465  0.083993  validation croisée\n",
              "2  DecisionTree_Bagging      FR  0.180239       NaN            hold-out\n",
              "3  DecisionTree_Bagging      DE  0.206300       NaN            hold-out\n",
              "4                   SVR      FR  0.242086       NaN            hold-out\n",
              "5                   SVR      DE  0.281272       NaN            hold-out\n",
              "6          RandomForest      FR  0.197303       NaN            hold-out\n",
              "7          RandomForest      DE  0.226403       NaN            hold-out\n",
              "8               XGBoost      FR  0.226692       NaN            hold-out\n",
              "9               XGBoost      DE  0.148815       NaN            hold-out"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 6) Tableau récapitulatif rapide (exécuter après les cellules précédentes)\n",
        "summary_rows = []\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree_KFold\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman\": fr_kfold[0],\n",
        "    \"std\": fr_kfold[1],\n",
        "    \"note\": \"validation croisée\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree_KFold\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman\": de_kfold[0],\n",
        "    \"std\": de_kfold[1],\n",
        "    \"note\": \"validation croisée\",\n",
        "})\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree_Bagging\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman\": bagging_fr_metrics[\"spearman_test\"],\n",
        "    \"std\": np.nan,\n",
        "    \"note\": \"hold-out\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"DecisionTree_Bagging\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman\": bagging_de_metrics[\"spearman_test\"],\n",
        "    \"std\": np.nan,\n",
        "    \"note\": \"hold-out\",\n",
        "})\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"SVR\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman\": svr_fr_metrics[\"spearman_test\"],\n",
        "    \"std\": np.nan,\n",
        "    \"note\": \"hold-out\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"SVR\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman\": svr_de_metrics[\"spearman_test\"],\n",
        "    \"std\": np.nan,\n",
        "    \"note\": \"hold-out\",\n",
        "})\n",
        "\n",
        "summary_rows.append({\n",
        "    \"model\": \"RandomForest\",\n",
        "    \"country\": \"FR\",\n",
        "    \"spearman\": rf_fr_metrics[\"spearman_test\"],\n",
        "    \"std\": np.nan,\n",
        "    \"note\": \"hold-out\",\n",
        "})\n",
        "summary_rows.append({\n",
        "    \"model\": \"RandomForest\",\n",
        "    \"country\": \"DE\",\n",
        "    \"spearman\": rf_de_metrics[\"spearman_test\"],\n",
        "    \"std\": np.nan,\n",
        "    \"note\": \"hold-out\",\n",
        "})\n",
        "\n",
        "if XGBOOST_AVAILABLE:\n",
        "    summary_rows.append({\n",
        "        \"model\": \"XGBoost\",\n",
        "        \"country\": \"FR\",\n",
        "        \"spearman\": xgb_fr_metrics[\"spearman_test\"],\n",
        "        \"std\": np.nan,\n",
        "        \"note\": \"hold-out\",\n",
        "    })\n",
        "    summary_rows.append({\n",
        "        \"model\": \"XGBoost\",\n",
        "        \"country\": \"DE\",\n",
        "        \"spearman\": xgb_de_metrics[\"spearman_test\"],\n",
        "        \"std\": np.nan,\n",
        "        \"note\": \"hold-out\",\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "display(summary_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion rapide\n",
        "- Les arbres ont maintenant deux références : K-Fold (pipeline historique) et Bagging (sans CV) pour vérifier l'impact de l'agrégation.\n",
        "- Les modèles SVR, Random Forest et XGBoost (optionnel) suivent exactement les mêmes données transformées et permettent de comparer facilement les Spearman.\n",
        "- Il suffit de lancer les cellules dans l'ordre pour mettre à jour les scores avant de reporter les meilleurs résultats dans le rapport final.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
